# Lecture 1
- ![L1.pdf](../assets/L1_1736443730816_0.pdf)
- What is Deep Learning?
	- ((678007b3-effa-477d-a5ff-6f13341d227c))
	- Based on computational models called neural networks
- What are neural networks?
	- $h=\sum_{i=1}^{M}wi.xi$
	- $y=a\left\lbrack h\right\rbrack$
- Minsly and Papert 1969
- Rumelhart, Hinton and williams, 1986 -> Backpropogation
- Deep Learning -> Early 2000s
- todo
-
-
- # Lecture 2
- ![L2_Slides.pdf](../assets/L2_Slides_1736444175435_0.pdf)
- Examples of Supervised learning
	- Regression, Multivariate Regression, Binary Classification, Multiclass Classification
- Types of Supervised Learning
	- Regression Problem : Model predicts real values
	- Classification problems: Model predicts discrete values
	- Simplest model => Linear Model => $f\left(x;\theta\right)=\theta0+\theta1.x$ => can only describe relationship as line.
	- ((67800a13-8223-4782-b31d-07f321d2e6e3))
- Piecewise Linear Function
	- can be made with help of activation function
	- Step or ReLU function
	- ((67800ae7-0bf0-4a60-b1f4-366f4273117f))
	- Unique excercise - check pdf
	- ((67800b64-eb73-46b0-8cde-e34830f019e4))
	-
	- What factors influence curves shape?
		- Number of parameters/weights
		- Types of activation functions: ReLU, Sigmoid, tanh
		- Data
	- How many linear regions or segments with D hidden units under ReLU activation?
		- ((67800c05-d458-46cb-bc66-d10e03fd838d))
	- With enough hidden units(linear regions), we can describe any 1D function with arbitrary accuracy
	- Universal approximation theorem
		- ((67800c6a-2978-4d79-b2bd-26cef992021e))
	- A deeper network can represent a given function with fewer parameters compared to wider network
	-
	-
- # Lecture 3
- ![L3_slides.pdf](../assets/L3_slides_1736445139169_0.pdf)
- Writing the basic quation from the figure
	- ((67800d08-e073-4d85-9339-1e96d715f378))
	- LATER ((67800d30-ffb3-4e4f-9c58-215ce8976b30))
	- How many parameters?
	- $3D+\left(K-1\right)D^2+\left(K-1\right)D+1$
	- Hyper-parameters
		- Number of layers
		- Number of hidden units
		- Learning rate
		- Batch size or mini-batch size
	- ## Key Benefits of Deep Neural Network
	- Hierarchical Representation - Edges, face parts, faces
	- Representation Learning
		- Machine learning technique that helps system automatically learn to represent raw data for subsequent tasks
	- ## Embedding Space?
	- TODO Check python package Visualtorch and torchview
- # Lecture 4
- in notebook [[Jan 10th, 2025]]
- ![L_4_5_6.pdf](../assets/L_4_5_6_1740759750982_0.pdf)
- Shallow network parameters
- ((67c1e2f6-1a59-4e0d-af70-7f37fc1dbf80))
- Deep Network Params
- ((67c1e30c-ca6c-4022-b6a8-ad1b110711e9))
- Optimization
	-
- # Lecture 5
	- [[Jan 15th, 2025]]
	-
-
-