# Lecture 1
	- ##
- # Lecture 2
	- ## Matter
		- Regular Expression
			- Range - [wW], [a-z], [A-Za-z]
			- Negation - [ ^Ss \] - neither S or s
				- [ ^ A-Z ] - neither A-Z
				- [e^] - look for either e or ^
				- a^b - look for a, ^, b
			- Optional - ? - Woodchucks?, Colou?rs? -> color, colors, colour, colours
			- OR - [a|b]
			- Multiple
				- t* -> 0 or more '',t, tt, ttt
				- b+ -> 1 or more
			- any character - . -> beg.n -> begin, began, begon ....
			- Finding all The - > (^| )[tT]he( |\.|$)
		- Accuracy or Precision -> Minimize false +ve
		- Recall  -> minimize false -ve
		- Morphology
			- TODO What is Morphology?
			- Two kind of knowledge
				- Orthographic rules - can solve woodchucks vs woodchuck
				- Morphological rules -  can solve goose vs geese
			- Why do we need to understand a language?
				- some language adds prefix or suffix to root word like english, hindi, latin
				- some languages such as tagalog add infix  or circumfix (german)
			- TODO Read about Automata Chapter 2 and 3 of Book
			- TODO Read about basic terminologies
			- Concatenative morphology is easy -  chapter 2 and 3
		- Stemming Methods
			- TODO Lemmatization, stemming, difference between these two?
		- Port Stemmer (1980)
			- 7 Sets of manual sequential rules
			- May not return valid stem word but guarantees if two word have same root they will be mapped similarly
			- All words are of the form (C)(VC)^m (V) ---- where C is consonent, V is vowel
				- consonent are letter other than A, E, I, O, U and Y preceeded by consonent
				- Trouble -> C(VC)^2
				- Apple -> (VC)^2
			- TODO Watch a video on how do the [[portstemmer]] work?
			-
- # Lecture 3
	- ## Matter
	- [[Levenshtein Distance]]
	- Statistical language Models
		- N-Grams
		- Benefits:
			- Machine Translation
			- Spelling Correction
			- Speech Recognition
- # Lecture 4
-