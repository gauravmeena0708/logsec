- {{video https://www.youtube.com/watch?v=w8F7_rQZxXk&list=PLdxQ7SoCLQANizknbIiHzL_hYjEaI-wUe&index=1}}
	- Summary
		- Review of stacked Auto Encoders
		- Basics of Probability
		- KL Divergence and its significance
		- Derivation of loss function for VAE
		- Coding the VAE in Google Colab
	- Stacked Auto-Encoders
		- Image Reconstruction
		- {{youtube-timestamp 147}} Input -> Encoder -> Bottleneck -> Decoder -> Output
		- Reconstruction loss $\mathcal{L}_{rec}(\phi,\theta)=\frac{1}{n}\sum_{i=1}^{n}(x_{i}-f_{\theta}(g_{\phi}(x_{i})))^2$
		-
		-
		-
		-
		-
	-
	-